 
----- Delete the target hdfs dir -----
> hdfs dfs -rm -R /data/wordcount/output
18/02/25 12:02:48 INFO fs.TrashPolicyDefault: Moved: 'hdfs://sandbox-hdp.hortonworks.com:8020/data/wordcount/output' to trash at: hdfs://sandbox-hdp.hortonworks.com:8020/user/azhang/.Trash/Current/data/wordcount/output
 
----- Launching Hadoop Job ---- 
 
  - Ignore the warning: 'WARN hdfs.DFSClient: Caught exception'
    Its a Hadoop bug described at: https://issues.apache.org/jira/browse/HDFS-10429
  
> hadoop jar ./target/mycompany.app-1.0.0-fat.jar com.mycompany.app.DriverNumReducers  /data/wordcount/input  /data/wordcount/output
18/02/25 12:02:50 INFO app.DriverNumReducers: Hadoop job Wordcount Job with # reducers
18/02/25 12:02:50 INFO app.DriverNumReducers:  Jar file       : [/home/azhang/workspace_mapR/my-app/./target/mycompany.app-1.0.0-fat.jar]
18/02/25 12:02:50 INFO app.DriverNumReducers:  Job parameters : [/data/wordcount/input, /data/wordcount/output]
18/02/25 12:02:50 INFO app.DriverNumReducers: Mapper
18/02/25 12:02:50 INFO app.DriverNumReducers:   - mapper class : class com.mycompany.app.WordcountMapper
18/02/25 12:02:50 INFO app.DriverNumReducers:   - output key class   : class org.apache.hadoop.io.Text
18/02/25 12:02:50 INFO app.DriverNumReducers:   - output value class : class org.apache.hadoop.io.IntWritable
18/02/25 12:02:50 INFO app.DriverNumReducers: Reducer
18/02/25 12:02:50 INFO app.DriverNumReducers:   - reducer class : class com.mycompany.app.WordcountReducer
18/02/25 12:02:50 INFO app.DriverNumReducers:   - # of reducers : 5
18/02/25 12:02:50 INFO app.DriverNumReducers: Combiner
18/02/25 12:02:50 INFO app.DriverNumReducers:   - combiner class : class com.mycompany.app.WordcountReducer
18/02/25 12:02:50 INFO app.DriverNumReducers: Input format class  : class org.apache.hadoop.mapreduce.lib.input.TextInputFormat
18/02/25 12:02:50 INFO app.DriverNumReducers: Output
18/02/25 12:02:50 INFO app.DriverNumReducers:   - format class : class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
18/02/25 12:02:50 INFO app.DriverNumReducers:   - key class    : class org.apache.hadoop.io.Text
18/02/25 12:02:50 INFO app.DriverNumReducers:   - value class  : class org.apache.hadoop.io.IntWritable
18/02/25 12:02:50 INFO app.DriverNumReducers: HDFS locations
18/02/25 12:02:50 INFO app.DriverNumReducers:   - Input  : /data/wordcount/input
18/02/25 12:02:50 INFO app.DriverNumReducers:   - Output : /data/wordcount/output
18/02/25 12:02:50 INFO client.RMProxy: Connecting to ResourceManager at sandbox-hdp.hortonworks.com/172.17.0.2:8032
18/02/25 12:02:51 INFO client.AHSProxy: Connecting to Application History server at sandbox-hdp.hortonworks.com/172.17.0.2:10200
18/02/25 12:02:51 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
18/02/25 12:02:51 INFO input.FileInputFormat: Total input paths to process : 3
18/02/25 12:02:52 INFO mapreduce.JobSubmitter: number of splits:3
18/02/25 12:02:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1519542449846_0004
18/02/25 12:02:53 INFO impl.YarnClientImpl: Submitted application application_1519542449846_0004
18/02/25 12:02:53 INFO mapreduce.Job: The url to track the job: http://sandbox-hdp.hortonworks.com:8088/proxy/application_1519542449846_0004/
18/02/25 12:02:53 INFO mapreduce.Job: Running job: job_1519542449846_0004
18/02/25 12:03:02 INFO mapreduce.Job: Job job_1519542449846_0004 running in uber mode : false
18/02/25 12:03:02 INFO mapreduce.Job:  map 0% reduce 0%
18/02/25 12:03:12 INFO mapreduce.Job:  map 67% reduce 0%
18/02/25 12:03:13 INFO mapreduce.Job:  map 100% reduce 0%
18/02/25 12:03:29 INFO mapreduce.Job:  map 100% reduce 20%
18/02/25 12:03:30 INFO mapreduce.Job:  map 100% reduce 60%
18/02/25 12:03:31 INFO mapreduce.Job:  map 100% reduce 80%
18/02/25 12:03:32 INFO mapreduce.Job:  map 100% reduce 100%
18/02/25 12:03:35 INFO mapreduce.Job: Job job_1519542449846_0004 completed successfully
18/02/25 12:03:35 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=806
		FILE: Number of bytes written=1227125
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=799
		HDFS: Number of bytes written=388
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Job Counters 
		Launched map tasks=3
		Launched reduce tasks=5
		Data-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=23242
		Total time spent by all reduces in occupied slots (ms)=74485
		Total time spent by all map tasks (ms)=23242
		Total time spent by all reduce tasks (ms)=74485
		Total vcore-milliseconds taken by all map tasks=23242
		Total vcore-milliseconds taken by all reduce tasks=74485
		Total megabyte-milliseconds taken by all map tasks=5810500
		Total megabyte-milliseconds taken by all reduce tasks=18621250
	Map-Reduce Framework
		Map input records=15
		Map output records=69
		Map output bytes=647
		Map output materialized bytes=866
		Input split bytes=423
		Combine input records=69
		Combine output records=68
		Reduce input groups=52
		Reduce shuffle bytes=866
		Reduce input records=68
		Reduce output records=52
		Spilled Records=136
		Shuffled Maps =15
		Failed Shuffles=0
		Merged Map outputs=15
		GC time elapsed (ms)=5286
		CPU time spent (ms)=9030
		Physical memory (bytes) snapshot=1305812992
		Virtual memory (bytes) snapshot=17169453056
		Total committed heap usage (bytes)=563609600
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=376
	File Output Format Counters 
		Bytes Written=388
 
----- List output in HDFS ----
 
> hdfs dfs -ls /data/wordcount/output/
Found 6 items
-rw-r--r--   1 azhang hdfs          0 2018-02-25 12:03 /data/wordcount/output/_SUCCESS
-rw-r--r--   1 azhang hdfs         37 2018-02-25 12:03 /data/wordcount/output/part-r-00000
-rw-r--r--   1 azhang hdfs        128 2018-02-25 12:03 /data/wordcount/output/part-r-00001
-rw-r--r--   1 azhang hdfs         63 2018-02-25 12:03 /data/wordcount/output/part-r-00002
-rw-r--r--   1 azhang hdfs         62 2018-02-25 12:03 /data/wordcount/output/part-r-00003
-rw-r--r--   1 azhang hdfs         98 2018-02-25 12:03 /data/wordcount/output/part-r-00004
 
----- Pull the results out cluster ----
 
> hdfs dfs -getmerge /data/wordcount/output /tmp/job_results.txt
 
----- List the local file ----
 
> cat /tmp/job_results.txt
But	1
The	1
forgets	1
never	2
with	1
A	2
An	2
And	1
Are	1
Hadoop	3
Sqoop	1
Useful	1
anything	1
bad	1
cling	1
data	1
gets	1
he	1
helps	1
in	1
is	4
king	2
lets	1
or	1
Hive	1
fellow	1
gentle	1
mad	1
the	2
well	1
what	1
wonderful	1
an	1
and	3
does	1
extraneous	1
group	1
thrive	1
to	1
yellow	2
Because	1
HDFS	1
He	2
Impala	1
Or	1
elegant	2
element	1
elephant	3
him	1
mellow	1
plays	1
thing	1
 
---- x x x ----
